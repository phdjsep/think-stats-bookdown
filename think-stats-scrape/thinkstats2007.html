<td valign="top" width="600">

<p>This HTML version of is provided for convenience, but it
is not the best format for the book.  In particular, some of the
symbols are not rendered correctly.

</p>
<p>You might prefer to read
the <a href="http://thinkstats2.com/thinkstats2.pdf">PDF version</a>, or
you can buy a hardcopy from
<a href="http://amzn.to/2gBBW7v">Amazon</a>.
</p>
<h1 id="sec58" class="chapter"><span style="font-size:medium">Chapter 6  Probability density functions</span></h1>
<p><span style="font-size:medium">
</span><a id="density"></a><span style="font-size:medium">
</span><a id="hevea_default473"></a><span style="font-size:medium">
</span><a id="hevea_default474"></a><span style="font-size:medium">
</span><a id="hevea_default475"></a><span style="font-size:medium">
</span><a id="hevea_default476"></a><span style="font-size:medium">
</span><a id="hevea_default477"></a><span style="font-size:medium">
</span><a id="hevea_default478"></a><span style="font-size:medium">
</span><a id="hevea_default479"></a><span style="font-size:medium">
</span><a id="hevea_default480"></a><span style="font-size:medium">
</span><a id="hevea_default481"></a><span style="font-size:medium">
</span><a id="hevea_default482"></a></p>
<p><span style="font-size:medium">The code for this chapter is in <span style="font-family:monospace">density.py</span>. For information
about downloading and working with this code, see Section </span><a href="thinkstats2001.html#code"><span style="font-size:medium">0.2</span></a><span style="font-size:medium">.</span></p>
<span style="font-size:medium">
</span><h2 id="sec59" class="section"><span style="font-size:medium">6.1  PDFs</span></h2>
<p><span style="font-size:medium">The derivative of a CDF is called a <span style="font-weight:bold">probability density function</span>,
or PDF. For example, the PDF of an exponential distribution is
</span></p>
<table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell">
<span style="font-style:italic;font-size:medium">PDF</span><sub><span style="font-style:italic;font-size:medium">expo</span></sub><span style="font-size:medium">(<span style="font-style:italic">x</span>) = λ <span style="font-style:italic">e</span></span><sup><span style="font-size:medium">−λ <span style="font-style:italic">x</span></span></sup><span style="font-size:medium">   </span>
</td></tr></table>
<p><span style="font-size:medium">
The PDF of a normal distribution is
</span></p>
<table class="display dcenter"><tr style="vertical-align:middle">
<td class="dcell">
<span style="font-style:italic;font-size:medium">PDF</span><sub><span style="font-style:italic;font-size:medium">normal</span></sub><span style="font-size:medium">(<span style="font-style:italic">x</span>) = </span>
</td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium">1</span></td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center"><table class="display"><tr style="vertical-align:middle">
<td class="dcell"><span style="font-size:medium">σ </span></td>
<td class="dcell"><span style="font-size:x-large">√</span></td>
<td class="dcell"><table style="border:0;border-spacing:1;border-collapse:separate;" class="cellpadding0">
<tr><td class="hbar"></td></tr>
<tr><td style="text-align:center;white-space:nowrap"><span style="font-size:medium">2 π</span></td></tr>
</table></td>
</tr></table></td></tr>
</table></td>
<td class="dcell"><span style="font-size:medium"> 
exp</span></td>
<td class="dcell"><span style="font-size:medium">⎡<br>
⎢<br>
⎢<br>
⎢<br>
⎢<br>
⎢<br>
⎣</span></td>
<td class="dcell"><span style="font-size:medium">−</span></td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium">1</span></td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium">2</span></td></tr>
</table></td>
<td class="dcell"><span style="font-size:medium"> 
</span></td>
<td class="dcell"><span style="font-size:medium">⎛<br>
⎜<br>
⎜<br>
⎝</span></td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium"><span style="font-style:italic">x</span> − µ</span></td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium">σ</span></td></tr>
</table></td>
<td class="dcell"><span style="font-size:medium"> </span></td>
<td class="dcell"><span style="font-size:medium">⎞<br>
⎟<br>
⎟<br>
⎠</span></td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:left"><span style="font-size:medium">2</span></td></tr>
<tr><td class="dcell" style="text-align:left"><span style="font-size:medium"><br><br><br></span></td></tr>
<tr><td class="dcell" style="text-align:left"><span style="font-size:medium"> </span></td></tr>
</table></td>
<td class="dcell"><span style="font-size:medium"> </span></td>
<td class="dcell"><span style="font-size:medium">⎤<br>
⎥<br>
⎥<br>
⎥<br>
⎥<br>
⎥<br>
⎦</span></td>
</tr></table>
<p><span style="font-size:medium">
Evaluating a PDF for a particular value of <span style="font-style:italic">x</span> is usually not useful.
The result is not a probability; it is a probability <em>density</em>.
</span><a id="hevea_default483"></a><span style="font-size:medium">
</span><a id="hevea_default484"></a></p>
<p><span style="font-size:medium">In physics, density is mass per unit of
volume; in order to get a mass, you have to multiply by volume or,
if the density is not constant, you have to integrate over volume.</span></p>
<p><span style="font-size:medium">Similarly, <span style="font-weight:bold">probability density</span> measures probability per unit of <span style="font-style:italic">x</span>.
In order to get a probability mass, you have to integrate over <span style="font-style:italic">x</span>.</span></p>
<p><span style="font-size:medium"><span style="font-family:monospace">thinkstats2</span> provides a class called Pdf that represents
a probability density function. Every Pdf object provides the
following methods:</span></p>
<ul class="itemize">
<li class="li-itemize"><span style="font-size:medium"><span style="font-family:monospace">Density</span>, which takes a value, <span style="font-family:monospace">x</span>, and returns the
density of the distribution at <span style="font-family:monospace">x</span>.</span></li>
<li class="li-itemize"><span style="font-size:medium"><span style="font-family:monospace">Render</span>, which evaluates the density at a discrete set of
values and returns a pair of sequences: the sorted values, <span style="font-family:monospace">xs</span>,
and their probability densities, <span style="font-family:monospace">ds</span>.</span></li>
<li class="li-itemize">
<span style="font-size:medium"><span style="font-family:monospace">MakePmf</span>, which evaluates <span style="font-family:monospace">Density</span>
at a discrete set of values and returns a normalized Pmf that
approximates the Pdf.
</span><a id="hevea_default485"></a>
</li>
<li class="li-itemize"><span style="font-size:medium"><span style="font-family:monospace">GetLinspace</span>, which returns the default set of points used 
by <span style="font-family:monospace">Render</span> and <span style="font-family:monospace">MakePmf</span>.</span></li>
</ul>
<p><span style="font-size:medium">Pdf is an abstract parent class, which means you should not
instantiate it; that is, you cannot create a Pdf object. Instead, you
should define a child class that inherits from Pdf and provides
definitions of <span style="font-family:monospace">Density</span> and <span style="font-family:monospace">GetLinspace</span>. Pdf provides
<span style="font-family:monospace">Render</span> and <span style="font-family:monospace">MakePmf</span>.</span></p>
<p><span style="font-size:medium">For example, <span style="font-family:monospace">thinkstats2</span> provides a class named <span style="font-family:monospace">NormalPdf</span> that evaluates the normal density function.</span></p>
<pre class="verbatim"><span style="font-size:medium">class NormalPdf(Pdf):

    def __init__(self, mu=0, sigma=1, label=''):
        self.mu = mu
        self.sigma = sigma
        self.label = label

    def Density(self, xs):
        return scipy.stats.norm.pdf(xs, self.mu, self.sigma)

    def GetLinspace(self):
        low, high = self.mu-3*self.sigma, self.mu+3*self.sigma
        return np.linspace(low, high, 101)
</span></pre>
<p><span style="font-size:medium">The NormalPdf object contains the parameters <span style="font-family:monospace">mu</span> and
<span style="font-family:monospace">sigma</span>. <span style="font-family:monospace">Density</span> uses
<span style="font-family:monospace">scipy.stats.norm</span>, which is an object that represents a normal
distribution and provides <span style="font-family:monospace">cdf</span> and <span style="font-family:monospace">pdf</span>, among other
methods (see Section </span><a href="thinkstats2006.html#normal"><span style="font-size:medium">5.2</span></a><span style="font-size:medium">).
</span><a id="hevea_default486"></a></p>
<p><span style="font-size:medium">The following example creates a NormalPdf with the mean and variance
of adult female heights, in cm, from the BRFSS (see
Section </span><a href="thinkstats2006.html#brfss"><span style="font-size:medium">5.4</span></a><span style="font-size:medium">). Then it computes the density of the
distribution at a location one standard deviation from the mean.
</span><a id="hevea_default487"></a></p>
<pre class="verbatim"><span style="font-size:medium">&gt;&gt;&gt; mean, var = 163, 52.8
&gt;&gt;&gt; std = math.sqrt(var)
&gt;&gt;&gt; pdf = thinkstats2.NormalPdf(mean, std)
&gt;&gt;&gt; pdf.Density(mean + std)
0.0333001
</span></pre>
<p><span style="font-size:medium">The result is about 0.03, in units of probability mass per cm.
Again, a probability density doesn’t mean much by itself. But if
we plot the Pdf, we can see the shape of the distribution:</span></p>
<pre class="verbatim"><span style="font-size:medium">&gt;&gt;&gt; thinkplot.Pdf(pdf, label='normal')
&gt;&gt;&gt; thinkplot.Show()
</span></pre>
<p><span style="font-size:medium"><span style="font-family:monospace">thinkplot.Pdf</span> plots the Pdf as a smooth function,
as contrasted with <span style="font-family:monospace">thinkplot.Pmf</span>, which renders a Pmf as a
step function. Figure </span><a href="#pdf_example"><span style="font-size:medium">6.1</span></a><span style="font-size:medium"> shows the result, as well
as a PDF estimated from a sample, which we’ll compute in the next
section.
</span><a id="hevea_default488"></a></p>
<p><span style="font-size:medium">You can use <span style="font-family:monospace">MakePmf</span> to approximate the Pdf:</span></p>
<pre class="verbatim"><span style="font-size:medium">&gt;&gt;&gt; pmf = pdf.MakePmf()
</span></pre>
<p><span style="font-size:medium">By default, the resulting Pmf contains 101 points equally spaced from
<span style="font-family:monospace">mu - 3*sigma</span> to <span style="font-family:monospace">mu + 3*sigma</span>. Optionally, <span style="font-family:monospace">MakePmf</span>
and <span style="font-family:monospace">Render</span> can take keyword arguments <span style="font-family:monospace">low</span>, <span style="font-family:monospace">high</span>,
and <span style="font-family:monospace">n</span>.</span></p>
<blockquote class="figure">
<div class="center"><hr style="width:80%;height:2"></div>
<span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="thinkstats2025.png"></span></div>
<span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 6.1: A normal PDF that models adult female height in the U.S.,
and the kernel density estimate of a sample with <span style="font-style:italic">n</span>=500.</span></td></tr></table></div>
<span style="font-size:medium">
</span><a id="pdf_example"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div>
</blockquote>
<span style="font-size:medium">
</span><h2 id="sec60" class="section"><span style="font-size:medium">6.2  Kernel density estimation</span></h2>
<p><span style="font-size:medium"><span style="font-weight:bold">Kernel density estimation</span> (KDE) is an algorithm that takes
a sample and finds an appropriately smooth PDF that fits 
the data. You can read details at
</span><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation"><span style="font-family:monospace;font-size:medium">http://en.wikipedia.org/wiki/Kernel_density_estimation</span></a><span style="font-size:medium">.
</span><a id="hevea_default489"></a><span style="font-size:medium">
</span><a id="hevea_default490"></a></p>
<p><span style="font-size:medium"><span style="font-family:monospace">scipy</span> provides an implementation of KDE and <span style="font-family:monospace">thinkstats2</span>
provides a class called <span style="font-family:monospace">EstimatedPdf</span> that uses it:
</span><a id="hevea_default491"></a><span style="font-size:medium">
</span><a id="hevea_default492"></a></p>
<pre class="verbatim"><span style="font-size:medium">class EstimatedPdf(Pdf):

    def __init__(self, sample):
        self.kde = scipy.stats.gaussian_kde(sample)

    def Density(self, xs):
        return self.kde.evaluate(xs)
</span></pre>
<p><span style="font-size:medium"><code>__init__</code> takes a sample
and computes a kernel density estimate. The result is a
<code>gaussian_kde</code> object that provides an <span style="font-family:monospace">evaluate</span>
method.</span></p>
<p><span style="font-size:medium"><span style="font-family:monospace">Density</span> takes a value or sequence, calls
<code>gaussian_kde.evaluate</code>, and returns the resulting density. The
word “Gaussian” appears in the name because it uses a filter based
on a Gaussian distribution to smooth the KDE. </span><a id="hevea_default493"></a></p>
<p><span style="font-size:medium">Here’s an example that generates a sample from a normal
distribution and then makes an EstimatedPdf to fit it:
</span><a id="hevea_default494"></a><span style="font-size:medium">
</span><a id="hevea_default495"></a></p>
<pre class="verbatim"><span style="font-size:medium">&gt;&gt;&gt; sample = [random.gauss(mean, std) for i in range(500)]
&gt;&gt;&gt; sample_pdf = thinkstats2.EstimatedPdf(sample)
&gt;&gt;&gt; thinkplot.Pdf(sample_pdf, label='sample KDE')
</span></pre>
<p><span style="font-size:medium"><code>sample</code> is a list of 500 random heights.
<code>sample_pdf</code> is a Pdf object that contains the estimated
KDE of the sample.
</span><a id="hevea_default496"></a><span style="font-size:medium">
</span><a id="hevea_default497"></a></p>
<p><span style="font-size:medium">Figure </span><a href="#pdf_example"><span style="font-size:medium">6.1</span></a><span style="font-size:medium"> shows the normal density function and a KDE
based on a sample of 500 random heights. The estimate is a good
match for the original distribution.</span></p>
<p><span style="font-size:medium">Estimating a density function with KDE is useful for several purposes:</span></p>
<ul class="itemize">
<li class="li-itemize">
<span style="font-size:medium"><span style="font-style:italic">Visualization:</span> During the exploration phase of a project, CDFs
are usually the best visualization of a distribution. After you
look at a CDF, you can decide whether an estimated PDF is an
appropriate model of the distribution. If so, it can be a better
choice for presenting the distribution to an audience that is
unfamiliar with CDFs.
</span><a id="hevea_default498"></a><span style="font-size:medium">
</span><a id="hevea_default499"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium"><span style="font-style:italic">Interpolation:</span> An estimated PDF is a way to get from a sample
to a model of the population. If you have reason to believe that
the population distribution is smooth, you can use KDE to interpolate
the density for values that don’t appear in the sample.
</span><a id="hevea_default500"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium"><span style="font-style:italic">Simulation:</span> Simulations are often based on the distribution
of a sample. If the sample size is small, it
might be appropriate to smooth the sample distribution using KDE,
which allows the simulation to explore more possible outcomes,
rather than replicating the observed data.
</span><a id="hevea_default501"></a>
</li>
</ul>
<span style="font-size:medium">
</span><h2 id="sec61" class="section"><span style="font-size:medium">6.3  The distribution framework</span></h2>
<p><span style="font-size:medium">
</span><a id="hevea_default502"></a></p>
<blockquote class="figure">
<div class="center"><hr style="width:80%;height:2"></div>
<span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="thinkstats2026.png"></span></div>
<span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 6.2: A framework that relates representations of distribution
functions.</span></td></tr></table></div>
<span style="font-size:medium">
</span><a id="dist_framework"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div>
</blockquote>
<p><span style="font-size:medium">At this point we have seen PMFs, CDFs and PDFs; let’s take a minute
to review. Figure </span><a href="#dist_framework"><span style="font-size:medium">6.2</span></a><span style="font-size:medium"> shows how these functions relate
to each other.
</span><a id="hevea_default503"></a><span style="font-size:medium">
</span><a id="hevea_default504"></a><span style="font-size:medium">
</span><a id="hevea_default505"></a></p>
<p><span style="font-size:medium">We started with PMFs, which represent the probabilities for a discrete
set of values. To get from a PMF to a CDF, you add up the probability
masses to get cumulative probabilities. 
To get from a CDF back to a PMF, you compute differences in cumulative
probabilities. We’ll see the implementation of these operations
in the next few sections.
</span><a id="hevea_default506"></a></p>
<p><span style="font-size:medium">A PDF is the derivative of a continuous CDF; or, equivalently,
a CDF is the integral of a PDF. Remember that a PDF maps from
values to probability densities; to get a probability, you have to
integrate.
</span><a id="hevea_default507"></a><span style="font-size:medium">
</span><a id="hevea_default508"></a><span style="font-size:medium">
</span><a id="hevea_default509"></a></p>
<p><span style="font-size:medium">To get from a discrete to a continuous distribution, you can perform
various kinds of smoothing. One form of smoothing is to assume that
the data come from an analytic continuous distribution
(like exponential or normal) and to estimate the parameters of that
distribution. Another option is kernel density estimation.
</span><a id="hevea_default510"></a><span style="font-size:medium">
</span><a id="hevea_default511"></a><span style="font-size:medium">
</span><a id="hevea_default512"></a><span style="font-size:medium">
</span><a id="hevea_default513"></a><span style="font-size:medium">
</span><a id="hevea_default514"></a><span style="font-size:medium">
</span><a id="hevea_default515"></a></p>
<p><span style="font-size:medium">The opposite of smoothing is <span style="font-weight:bold">discretizing</span>, or quantizing. If you
evaluate a PDF at discrete points, you can generate a PMF that is an
approximation of the PDF. You can get a better approximation using
numerical integration. </span><a id="hevea_default516"></a><span style="font-size:medium">
</span><a id="hevea_default517"></a><span style="font-size:medium">
</span><a id="hevea_default518"></a></p>
<p><span style="font-size:medium">To distinguish between continuous and discrete CDFs, it might be
better for a discrete CDF to be a “cumulative mass function,” but as
far as I can tell no one uses that term. </span><a id="hevea_default519"></a></p>
<span style="font-size:medium">
</span><h2 id="sec62" class="section"><span style="font-size:medium">6.4  Hist implementation</span></h2>
<p><span style="font-size:medium">At this point you should know how to use the basic types provided
by <span style="font-family:monospace">thinkstats2</span>: Hist, Pmf, Cdf, and Pdf. The next few sections
provide details about how they are implemented. This material
might help you use these classes more effectively, but it is not
strictly necessary.
</span><a id="hevea_default520"></a></p>
<p><span style="font-size:medium">Hist and Pmf inherit from a parent class called <code>_DictWrapper</code>.
The leading underscore indicates that this class is “internal;” that
is, it should not be used by code in other modules. The name
indicates what it is: a dictionary wrapper. Its primary attribute is
<span style="font-family:monospace">d</span>, the dictionary that maps from values to their frequencies.
</span><a id="hevea_default521"></a><span style="font-size:medium">
</span><a id="hevea_default522"></a><span style="font-size:medium">
</span><a id="hevea_default523"></a></p>
<p><span style="font-size:medium">The values can be any hashable type. The frequencies should be integers,
but can be any numeric type.
</span><a id="hevea_default524"></a></p>
<p><span style="font-size:medium"><code>_DictWrapper</code> contains methods appropriate for both
Hist and Pmf, including <code>__init__</code>, <span style="font-family:monospace">Values</span>,
<span style="font-family:monospace">Items</span> and <span style="font-family:monospace">Render</span>. It also provides modifier
methods <span style="font-family:monospace">Set</span>, <span style="font-family:monospace">Incr</span>, <span style="font-family:monospace">Mult</span>, and <span style="font-family:monospace">Remove</span>. These
methods are all implemented with dictionary operations. For example:
</span><a id="hevea_default525"></a></p>
<pre class="verbatim"><span style="font-size:medium"># class _DictWrapper

    def Incr(self, x, term=1):
        self.d[x] = self.d.get(x, 0) + term

    def Mult(self, x, factor):
        self.d[x] = self.d.get(x, 0) * factor

    def Remove(self, x):
        del self.d[x]
</span></pre>
<p><span style="font-size:medium">Hist also provides <span style="font-family:monospace">Freq</span>, which looks up the frequency
of a given value.
</span><a id="hevea_default526"></a></p>
<p><span style="font-size:medium">Because Hist operators and methods are based on dictionaries,
these methods are constant time operations;
that is, their run time does not increase as the Hist gets bigger.
</span><a id="hevea_default527"></a></p>
<span style="font-size:medium">
</span><h2 id="sec63" class="section"><span style="font-size:medium">6.5  Pmf implementation</span></h2>
<p><span style="font-size:medium">Pmf and Hist are almost the same thing, except that a Pmf
maps values to floating-point probabilities, rather than integer
frequencies. If the sum of the probabilities is 1, the Pmf is normalized.
</span><a id="hevea_default528"></a></p>
<p><span style="font-size:medium">Pmf provides <span style="font-family:monospace">Normalize</span>, which computes the sum of the
probabilities and divides through by a factor:</span></p>
<pre class="verbatim"><span style="font-size:medium"># class Pmf

    def Normalize(self, fraction=1.0):
        total = self.Total()
        if total == 0.0:
            raise ValueError('Total probability is zero.')

        factor = float(fraction) / total
        for x in self.d:
            self.d[x] *= factor

        return total
</span></pre>
<p><span style="font-size:medium"><span style="font-family:monospace">fraction</span> determines the sum of the probabilities after
normalizing; the default value is 1. If the total probability is 0,
the Pmf cannot be normalized, so <span style="font-family:monospace">Normalize</span> raises <span style="font-family:monospace">ValueError</span>.</span></p>
<p><span style="font-size:medium">Hist and Pmf have the same constructor. It can take
as an argument a <span style="font-family:monospace">dict</span>, Hist, Pmf or Cdf, a pandas
Series, a list of (value, frequency) pairs, or a sequence of values.
</span><a id="hevea_default529"></a></p>
<p><span style="font-size:medium">If you instantiate a Pmf, the result is normalized. If you
instantiate a Hist, it is not. To construct an unnormalized Pmf,
you can create an empty Pmf and modify it. The Pmf modifiers do
not renormalize the Pmf.</span></p>
<span style="font-size:medium">
</span><h2 id="sec64" class="section"><span style="font-size:medium">6.6  Cdf implementation</span></h2>
<p><span style="font-size:medium">A CDF maps from values to cumulative probabilities, so I could have
implemented Cdf as a <code>_DictWrapper</code>. But the values in a CDF are
ordered and the values in a <code>_DictWrapper</code> are not. Also, it is
often useful to compute the inverse CDF; that is, the map from
cumulative probability to value. So the implementaion I chose is two
sorted lists. That way I can use binary search to do a forward or
inverse lookup in logarithmic time.
</span><a id="hevea_default530"></a><span style="font-size:medium">
</span><a id="hevea_default531"></a><span style="font-size:medium">
</span><a id="hevea_default532"></a><span style="font-size:medium">
</span><a id="hevea_default533"></a><span style="font-size:medium">
</span><a id="hevea_default534"></a><span style="font-size:medium">
</span><a id="hevea_default535"></a></p>
<p><span style="font-size:medium">The Cdf constructor can take as a parameter a sequence of values
or a pandas Series, a dictionary that maps from values to
probabilities, a sequence of (value, probability) pairs, a Hist, Pmf,
or Cdf. Or if it is given two parameters, it treats them as a sorted
sequence of values and the sequence of corresponding cumulative
probabilities.</span></p>
<p><span style="font-size:medium">Given a sequence, pandas Series, or dictionary, the constructor makes
a Hist. Then it uses the Hist to initialize the attributes:</span></p>
<pre class="verbatim"><span style="font-size:medium">        self.xs, freqs = zip(*sorted(dw.Items()))
        self.ps = np.cumsum(freqs, dtype=np.float)
        self.ps /= self.ps[-1]
</span></pre>
<p><span style="font-size:medium"><span style="font-family:monospace">xs</span> is the sorted list of values; <span style="font-family:monospace">freqs</span> is the list
of corresponding frequencies. <span style="font-family:monospace">np.cumsum</span> computes
the cumulative sum of the frequencies. Dividing through by the
total frequency yields cumulative probabilities.
For <span style="font-family:monospace">n</span> values, the time to construct the
Cdf is proportional to <span style="font-style:italic">n</span> log<span style="font-style:italic">n</span>.
</span><a id="hevea_default536"></a></p>
<p><span style="font-size:medium">Here is the implementation of <span style="font-family:monospace">Prob</span>, which takes a value
and returns its cumulative probability: </span></p>
<pre class="verbatim"><span style="font-size:medium"># class Cdf
    def Prob(self, x):
        if x &lt; self.xs[0]:
            return 0.0
        index = bisect.bisect(self.xs, x)
        p = self.ps[index - 1]
        return p
</span></pre>
<p><span style="font-size:medium">The <span style="font-family:monospace">bisect</span> module provides an implementation of binary search.
And here is the implementation of <span style="font-family:monospace">Value</span>, which takes a
cumulative probability and returns the corresponding value:</span></p>
<pre class="verbatim"><span style="font-size:medium"># class Cdf
    def Value(self, p):
        if p &lt; 0 or p &gt; 1:
            raise ValueError('p must be in range [0, 1]')

        index = bisect.bisect_left(self.ps, p)
        return self.xs[index]
</span></pre>
<p><span style="font-size:medium">Given a Cdf, we can compute the Pmf by computing differences between
consecutive cumulative probabilities. If you call the Cdf constructor
and pass a Pmf, it computes differences by calling <span style="font-family:monospace">Cdf.Items</span>:
</span><a id="hevea_default537"></a><span style="font-size:medium">
</span><a id="hevea_default538"></a></p>
<pre class="verbatim"><span style="font-size:medium"># class Cdf
    def Items(self):
        a = self.ps
        b = np.roll(a, 1)
        b[0] = 0
        return zip(self.xs, a-b)
</span></pre>
<p><span style="font-size:medium"><span style="font-family:monospace">np.roll</span> shifts the elements of <span style="font-family:monospace">a</span> to the right, and “rolls”
the last one back to the beginning. We replace the first element of
<span style="font-family:monospace">b</span> with 0 and then compute the difference <span style="font-family:monospace">a-b</span>. The result
is a NumPy array of probabilities.
</span><a id="hevea_default539"></a></p>
<p><span style="font-size:medium">Cdf provides <span style="font-family:monospace">Shift</span> and <span style="font-family:monospace">Scale</span>, which modify the
values in the Cdf, but the probabilities should be treated as
immutable.</span></p>
<span style="font-size:medium">
</span><h2 id="sec65" class="section"><span style="font-size:medium">6.7  Moments</span></h2>
<p><span style="font-size:medium">
</span><a id="hevea_default540"></a></p>
<p><span style="font-size:medium">Any time you take a sample and reduce it to a single number, that
number is a statistic. The statistics we have seen so far include
mean, variance, median, and interquartile range.</span></p>
<p><span style="font-size:medium">A <span style="font-weight:bold">raw moment</span> is a kind of statistic. If you have a sample of
values, <span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">i</span></sub><span style="font-size:medium">, the <span style="font-style:italic">k</span>th raw moment is:
</span></p>
<table class="display dcenter"><tr style="vertical-align:middle">
<td class="dcell">
<span style="font-size:medium"><span style="font-style:italic">m</span>′</span><sub><span style="font-style:italic;font-size:medium">k</span></sub><span style="font-size:medium"> = </span>
</td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium">1</span></td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-style:italic;font-size:medium">n</span></td></tr>
</table></td>
<td class="dcell"><span style="font-size:medium"> </span></td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium"> </span></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-size:xx-large">∑</span></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-style:italic;font-size:medium">i</span></td></tr>
</table></td>
<td class="dcell">
<span style="font-size:medium"> <span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">i</span></sub><sup><span style="font-style:italic;font-size:medium">k</span></sup><span style="font-size:medium"> </span>
</td>
</tr></table>
<p><span style="font-size:medium">
Or if you prefer Python notation:</span></p>
<pre class="verbatim"><span style="font-size:medium">def RawMoment(xs, k):
    return sum(x**k for x in xs) / len(xs)
</span></pre>
<p><span style="font-size:medium">When <span style="font-style:italic">k</span>=1 the result is the sample mean, <span style="text-decoration:overline">x</span>. The other
raw moments don’t mean much by themselves, but they are used
in some computations.</span></p>
<p><span style="font-size:medium">The <span style="font-weight:bold">central moments</span> are more useful. The
<span style="font-style:italic">k</span>th central moment is:
</span></p>
<table class="display dcenter"><tr style="vertical-align:middle">
<td class="dcell">
<span style="font-style:italic;font-size:medium">m</span><sub><span style="font-style:italic;font-size:medium">k</span></sub><span style="font-size:medium"> = </span>
</td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium">1</span></td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-style:italic;font-size:medium">n</span></td></tr>
</table></td>
<td class="dcell"><span style="font-size:medium"> </span></td>
<td class="dcell"><table class="display">
<tr><td class="dcell" style="text-align:center"><span style="font-size:medium"> </span></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-size:xx-large">∑</span></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-style:italic;font-size:medium">i</span></td></tr>
</table></td>
<td class="dcell">
<span style="font-size:medium"> (<span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">i</span></sub><span style="font-size:medium"> − <span style="text-decoration:overline">x</span>)</span><sup><span style="font-style:italic;font-size:medium">k</span></sup><span style="font-size:medium"> </span>
</td>
</tr></table>
<p><span style="font-size:medium">
Or in Python:</span></p>
<pre class="verbatim"><span style="font-size:medium">def CentralMoment(xs, k):
    mean = RawMoment(xs, 1)
    return sum((x - mean)**k for x in xs) / len(xs)
</span></pre>
<p><span style="font-size:medium">When <span style="font-style:italic">k</span>=2 the result is the second central moment, which you might
recognize as variance. The definition of variance gives a hint about
why these statistics are called moments. If we attach a weight along a
ruler at each location, <span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">i</span></sub><span style="font-size:medium">, and then spin the ruler around
the mean, the moment of inertia of the spinning weights is the variance
of the values. If you are not familiar with moment of inertia, see
</span><a href="http://en.wikipedia.org/wiki/Moment_of_inertia"><span style="font-family:monospace;font-size:medium">http://en.wikipedia.org/wiki/Moment_of_inertia</span></a><span style="font-size:medium">. </span><a id="hevea_default541"></a></p>
<p><span style="font-size:medium">When you report moment-based statistics, it is important to think
about the units. For example, if the values <span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">i</span></sub><span style="font-size:medium"> are in cm, the
first raw moment is also in cm. But the second moment is in
cm</span><sup><span style="font-size:medium">2</span></sup><span style="font-size:medium">, the third moment is in cm</span><sup><span style="font-size:medium">3</span></sup><span style="font-size:medium">, and so on.</span></p>
<p><span style="font-size:medium">Because of these units, moments are hard to interpret by themselves.
That’s why, for the second moment, it is common to report standard
deviation, which is the square root of variance, so it is in the same
units as <span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">i</span></sub><span style="font-size:medium">.
</span><a id="hevea_default542"></a></p>
<span style="font-size:medium">
</span><h2 id="sec66" class="section"><span style="font-size:medium">6.8  Skewness</span></h2>
<p><span style="font-size:medium">
</span><a id="hevea_default543"></a></p>
<p><span style="font-size:medium"><span style="font-weight:bold">Skewness</span> is a property that describes the shape of a distribution.
If the distribution is symmetric around its central tendency, it is
unskewed. If the values extend farther to the right, it is “right
skewed” and if the values extend left, it is “left skewed.”
</span><a id="hevea_default544"></a></p>
<p><span style="font-size:medium">This use of “skewed” does not have the usual connotation of
“biased.” Skewness only describes the shape of the distribution;
it says nothing about whether the sampling process might have been
biased.
</span><a id="hevea_default545"></a><span style="font-size:medium">
</span><a id="hevea_default546"></a></p>
<p><span style="font-size:medium">Several statistics are commonly used to quantify the skewness of a
distribution. Given a sequence of values, <span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">i</span></sub><span style="font-size:medium">, the <span style="font-weight:bold">sample
skewness</span>, <span style="font-style:italic">g</span></span><sub><span style="font-size:medium">1</span></sub><span style="font-size:medium">, can be computed like this:</span></p>
<pre class="verbatim"><span style="font-size:medium">def StandardizedMoment(xs, k):
    var = CentralMoment(xs, 2)
    std = math.sqrt(var)
    return CentralMoment(xs, k) / std**k

def Skewness(xs):
    return StandardizedMoment(xs, 3)
</span></pre>
<p><span style="font-style:italic;font-size:medium">g</span><sub><span style="font-size:medium">1</span></sub><span style="font-size:medium"> is the third <span style="font-weight:bold">standardized moment</span>, which means that it has
been normalized so it has no units.
</span><a id="hevea_default547"></a></p>
<p><span style="font-size:medium">Negative skewness indicates that a distribution 
skews left; positive skewness indicates
that a distribution skews right. The magnitude of <span style="font-style:italic">g</span></span><sub><span style="font-size:medium">1</span></sub><span style="font-size:medium"> indicates
the strength of the skewness, but by itself it is not easy to
interpret.</span></p>
<p><span style="font-size:medium">In practice, computing sample skewness is usually not
a good idea. If there are any outliers, they
have a disproportionate effect on <span style="font-style:italic">g</span></span><sub><span style="font-size:medium">1</span></sub><span style="font-size:medium">.
</span><a id="hevea_default548"></a></p>
<p><span style="font-size:medium">Another way to evaluate the asymmetry of a distribution is to look
at the relationship between the mean and median.
Extreme values have more effect on the mean than the median, so
in a distribution that skews left, the mean is less than the median.
In a distribution that skews right, the mean is greater.
</span><a id="hevea_default549"></a><span style="font-size:medium">
</span><a id="hevea_default550"></a></p>
<p><span style="font-size:medium"><span style="font-weight:bold">Pearson’s median skewness coefficient</span> is a measure
of skewness based on the difference between the
sample mean and median:
</span></p>
<table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell">
<span style="font-style:italic;font-size:medium">g</span><sub><span style="font-style:italic;font-size:medium">p</span></sub><span style="font-size:medium"> = 3 (<span style="text-decoration:overline">x</span> − <span style="font-style:italic">m</span>) / <span style="font-style:italic">S</span> </span>
</td></tr></table>
<p><span style="font-size:medium">
Where <span style="text-decoration:overline">x</span> is the sample mean, <span style="font-style:italic">m</span> is the median, and
<span style="font-style:italic">S</span> is the standard deviation. Or in Python:
</span><a id="hevea_default551"></a></p>
<pre class="verbatim"><span style="font-size:medium">def Median(xs):
    cdf = thinkstats2.Cdf(xs)
    return cdf.Value(0.5)

def PearsonMedianSkewness(xs):
    median = Median(xs)
    mean = RawMoment(xs, 1)
    var = CentralMoment(xs, 2)
    std = math.sqrt(var)
    gp = 3 * (mean - median) / std
    return gp
</span></pre>
<p><span style="font-size:medium">This statistic is <span style="font-weight:bold">robust</span>, which means that it is less vulnerable
to the effect of outliers.
</span><a id="hevea_default552"></a><span style="font-size:medium">
</span><a id="hevea_default553"></a></p>
<blockquote class="figure">
<div class="center"><hr style="width:80%;height:2"></div>
<span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="thinkstats2027.png"></span></div>
<span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 6.3: Estimated PDF of birthweight data from the NSFG.</span></td></tr></table></div>
<span style="font-size:medium">
</span><a id="density_totalwgt_kde"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div>
</blockquote>
<p><span style="font-size:medium">As an example, let’s look at the skewness of birth weights in the
NSFG pregnancy data. Here’s the code to estimate and plot the PDF:
</span><a id="hevea_default554"></a></p>
<pre class="verbatim"><span style="font-size:medium">    live, firsts, others = first.MakeFrames()
    data = live.totalwgt_lb.dropna()
    pdf = thinkstats2.EstimatedPdf(data)
    thinkplot.Pdf(pdf, label='birth weight')
</span></pre>
<p><span style="font-size:medium">Figure </span><a href="#density_totalwgt_kde"><span style="font-size:medium">6.3</span></a><span style="font-size:medium"> shows the result. The left tail appears
longer than the right, so we suspect the distribution is skewed left.
The mean, 7.27 lbs, is a bit less than
the median, 7.38 lbs, so that is consistent with left skew.
And both skewness coefficients are negative:
sample skewness is -0.59;
Pearson’s median skewness is -0.23.
</span><a id="hevea_default555"></a><span style="font-size:medium">
</span><a id="hevea_default556"></a><span style="font-size:medium">
</span><a id="hevea_default557"></a></p>
<blockquote class="figure">
<div class="center"><hr style="width:80%;height:2"></div>
<span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="thinkstats2028.png"></span></div>
<span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 6.4: Estimated PDF of adult weight data from the BRFSS.</span></td></tr></table></div>
<span style="font-size:medium">
</span><a id="density_wtkg2_kde"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div>
</blockquote>
<p><span style="font-size:medium">Now let’s compare this distribution to the distribution of adult
weight in the BRFSS. Again, here’s the code:
</span><a id="hevea_default558"></a></p>
<pre class="verbatim"><span style="font-size:medium">    df = brfss.ReadBrfss(nrows=None)
    data = df.wtkg2.dropna()
    pdf = thinkstats2.EstimatedPdf(data)
    thinkplot.Pdf(pdf, label='adult weight')
</span></pre>
<p><span style="font-size:medium">Figure </span><a href="#density_wtkg2_kde"><span style="font-size:medium">6.4</span></a><span style="font-size:medium"> shows the result. The distribution
appears skewed to the right. Sure enough, the mean, 79.0, is bigger
than the median, 77.3. The sample skewness is 1.1 and Pearson’s
median skewness is 0.26.
</span><a id="hevea_default559"></a><span style="font-size:medium">
</span><a id="hevea_default560"></a></p>
<p><span style="font-size:medium">The sign of the skewness coefficient indicates whether the distribution
skews left or right, but other than that, they are hard to interpret.
Sample skewness is less robust; that is, it is more
susceptible to outliers. As a result it is less reliable
when applied to skewed distributions, exactly when it would be most
relevant.
</span><a id="hevea_default561"></a><span style="font-size:medium">
</span><a id="hevea_default562"></a></p>
<p><span style="font-size:medium">Pearson’s median skewness is based on a computed mean and variance,
so it is also susceptible to outliers, but since it does not depend
on a third moment, it is somewhat more robust.
</span><a id="hevea_default563"></a></p>
<span style="font-size:medium">
</span><h2 id="sec67" class="section"><span style="font-size:medium">6.9  Exercises</span></h2>
<p><span style="font-size:medium">A solution to this exercise is in <code>chap06soln.py</code>.</span></p>
<div class="theorem">
<span style="font-size:medium"><span style="font-weight:bold">Exercise 1</span>  </span><p><span style="font-size:medium"><em>The distribution of income is famously skewed to the right. In this
exercise, we’ll measure how strong that skew is.
</em></span><a id="hevea_default564"></a><span style="font-size:medium">
</span><a id="hevea_default565"></a></p>
<p><span style="font-size:medium"><em>The Current Population Survey (CPS) is a joint effort of the Bureau
of Labor Statistics and the Census Bureau to study income and related
variables. Data collected in 2013 is available from
</em></span><a href="http://www.census.gov/hhes/www/cpstables/032013/hhinc/toc.htm"><span style="font-family:monospace;font-size:medium"><em>http://www.census.gov/hhes/www/cpstables/032013/hhinc/toc.htm</em></span></a><span style="font-size:medium"><em>.
I downloaded <span style="font-family:monospace">hinc06.xls</span>, which is an Excel spreadsheet with
information about household income, and converted it to <span style="font-family:monospace">hinc06.csv</span>,
a CSV file you will find in the repository for this book. You
will also find <span style="font-family:monospace">hinc2.py</span>, which reads this file and transforms
the data.
</em></span><a id="hevea_default566"></a><span style="font-size:medium">
</span><a id="hevea_default567"></a><span style="font-size:medium">
</span><a id="hevea_default568"></a></p>
<p><span style="font-size:medium"><em>The dataset is in the form of a series of income ranges and the number
of respondents who fell in each range. The lowest range includes
respondents who reported annual household income “Under $5000.”
The highest range includes respondents who made “$250,000 or
more.”</em></span></p>
<p><span style="font-size:medium"><em>To estimate mean and other statistics from these data, we have to
make some assumptions about the lower and upper bounds, and how
the values are distributed in each range. <span style="font-family:monospace">hinc2.py</span> provides
<span style="font-family:monospace">InterpolateSample</span>, which shows one way to model
this data. It takes a DataFrame with a column, <span style="font-family:monospace">income</span>, that
contains the upper bound of each range, and <span style="font-family:monospace">freq</span>, which contains
the number of respondents in each frame.
</em></span><a id="hevea_default569"></a><span style="font-size:medium">
</span><a id="hevea_default570"></a></p>
<p><span style="font-size:medium"><em>It also takes <code>log_upper</code>, which is an assumed upper bound
on the highest range, expressed in <span style="font-family:monospace">log10</span> dollars. 
The default value, <code>log_upper=6.0</code> represents the assumption
that the largest income among the respondents is
</em>10</span><sup><span style="font-size:medium">6</span></sup><span style="font-size:medium"><em>, or one million dollars.</em></span></p>
<p><span style="font-size:medium"><em><span style="font-family:monospace">InterpolateSample</span> generates a pseudo-sample; that is, a sample
of household incomes that yields the same number of respondents
in each range as the actual data. It assumes that incomes in
each range are equally spaced on a log10 scale.</em></span></p>
<p><span style="font-size:medium"><em>Compute the median, mean, skewness and Pearson’s skewness of the
resulting sample. What fraction of households reports a taxable
income below the mean? How do the results depend on the assumed
upper bound?
</em></span></p>
</div>
<span style="font-size:medium">
</span><h2 id="sec68" class="section"><span style="font-size:medium">6.10  Glossary</span></h2>
<ul class="itemize">
<li class="li-itemize">
<span style="font-size:medium">Probability density function (PDF): The derivative of a continuous CDF,
a function that maps a value to its probability density.
</span><a id="hevea_default571"></a><span style="font-size:medium">
</span><a id="hevea_default572"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">Probability density: A quantity that can be integrated over a
range of values to yield a probability. If the values are in units
of cm, for example, probability density is in units of probability
per cm.
</span><a id="hevea_default573"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">Kernel density estimation (KDE): An algorithm that estimates a PDF
based on a sample.
</span><a id="hevea_default574"></a><span style="font-size:medium">
</span><a id="hevea_default575"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">discretize: To approximate a continuous function or distribution
with a discrete function. The opposite of smoothing.
</span><a id="hevea_default576"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">raw moment: A statistic based on the sum of data raised to a power.
</span><a id="hevea_default577"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">central moment: A statistic based on deviation from the mean,
raised to a power.
</span><a id="hevea_default578"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">standardized moment: A ratio of moments that has no units.
</span><a id="hevea_default579"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">skewness: A measure of how asymmetric a distribution is.
</span><a id="hevea_default580"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">sample skewness: A moment-based statistic intended to quantify
the skewness of a distribution.
</span><a id="hevea_default581"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">Pearson’s median skewness coefficient: A statistic intended to
quantify the skewness of a distribution based on the median, mean,
and standard deviation.
</span><a id="hevea_default582"></a>
</li>
<li class="li-itemize">
<span style="font-size:medium">robust: A statistic is robust if it is relatively immune to the
effect of outliers.
</span><a id="hevea_default583"></a>
</li>
</ul>
<span style="font-size:medium">
</span>
</td>